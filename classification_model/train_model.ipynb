{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jivan/anaconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import videotransforms\n",
    "import matplotlib as plt\n",
    "from dataset import Dataset, calculate_accuracy, make_dataset\n",
    "from timm.models import create_model\n",
    "from utils import custom_collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    videotransforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    videotransforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 31\n",
    "root = '../../Desktop/MLResearch/i3d_smarthome/mp4/'\n",
    "batch_size = 16\n",
    "protocol = \"CS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file not found: ../../Desktop/MLResearch/i3d_smarthome/mp4/Pour.Fromcup_p13_r01_v20_c06.mp4\n",
      "Video file not found: ../../Desktop/MLResearch/i3d_smarthome/mp4/Pour.Fromcup_p13_r00_v20_c06.mp4\n",
      "Video file not found: ../../Desktop/MLResearch/i3d_smarthome/mp4/Pour.Fromcup_p19_r00_v08_c01.mp4\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('./splits/train_cs.txt', 'train', root, \"rgb\", train_transforms, protocol)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "val_dataset = Dataset('./splits/validation_cs.txt', 'val', root, \"rgb\", test_transforms, protocol)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n",
    "datasets = {'train': train_dataset, 'val': val_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in the first video: 64\n",
      "Shape of the video tensor: torch.Size([3, 64, 224, 224])\n",
      "Label of the first video: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       dtype=torch.float64)\n",
      "Number of frames in the second video: 48\n",
      "Number of frames in the first validation video: 64\n",
      "Shape of the validation video tensor: torch.Size([3, 64, 224, 224])\n",
      "Label of the first validation video: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Access the first entry in the training dataset\n",
    "first_video, first_label = datasets['train'][0]\n",
    "second_video, second_label = datasets['train'][1]\n",
    "\n",
    "# Print the number of frames and the shape of the video tensor\n",
    "print(f\"Number of frames in the first video: {first_video.shape[1]}\")\n",
    "print(f\"Shape of the video tensor: {first_video.shape}\")\n",
    "print(f\"Label of the first video: {first_label}\")\n",
    "\n",
    "print(f\"Number of frames in the second video: {second_video.shape[1]}\")\n",
    "\n",
    "# Repeat for the validation dataset\n",
    "first_val_video, first_val_label = datasets['val'][0]\n",
    "\n",
    "print(f\"Number of frames in the first validation video: {first_val_video.shape[1]}\")\n",
    "print(f\"Shape of the validation video tensor: {first_val_video.shape}\")\n",
    "print(f\"Label of the first validation video: {first_val_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model (swin transformer)\n",
    "model = create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=num_classes)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jivan/anaconda3/envs/torch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# define learning rate and optimizer\n",
    "init_lr = 0.01\n",
    "optimizer = optim.AdamW(model.parameters(), lr=init_lr, weight_decay=0.01)\n",
    "lr_sched = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation function\n",
    "def run_training(max_steps=100, save_model='weights/'):\n",
    "    steps = 0\n",
    "    while steps < max_steps:\n",
    "        print(f'Step {steps}/{max_steps}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            tot_loss = 0.0\n",
    "            tot_cls_loss = 0.0\n",
    "            tot_acc = 0.0\n",
    "            num_iter = 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for data in dataloaders[phase]:\n",
    "                num_iter += 1\n",
    "                inputs, labels = data\n",
    "                inputs = Variable(inputs.to(device))\n",
    "                labels = Variable(labels.to(device))\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                criterion = nn.CrossEntropyLoss().to(device)\n",
    "                cls_loss = criterion(outputs, torch.max(labels, dim=1)[1].long())\n",
    "                tot_cls_loss += cls_loss.data\n",
    "\n",
    "                loss = cls_loss\n",
    "                tot_loss += loss.data\n",
    "                loss.backward()\n",
    "                acc = calculate_accuracy(outputs, torch.max(labels, dim=1)[1])\n",
    "                tot_acc += acc\n",
    "                if phase == 'train':\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            if phase == 'train':\n",
    "                print(f'{phase} Cls Loss: {tot_cls_loss/num_iter:.4f} Tot Loss: {tot_loss/num_iter:.4f}, Acc: {tot_acc/num_iter:.4f}')\n",
    "                torch.save(model.module.state_dict(), os.path.join(save_model, f'{steps:06d}.pt'))\n",
    "                tot_loss = tot_cls_loss = tot_acc = 0.0\n",
    "                steps += 1\n",
    "            if phase == 'val':\n",
    "                lr_sched.step(tot_cls_loss/num_iter)\n",
    "                print(f'{phase} Cls Loss: {tot_cls_loss/num_iter:.4f} Tot Loss: {tot_loss/num_iter:.4f}, Acc: {tot_acc/num_iter:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/100\n",
      "----------\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m run_training(max_steps\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, save_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mweights/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m inputs \u001b[39m=\u001b[39m Variable(inputs\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m labels \u001b[39m=\u001b[39m Variable(labels\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jivan/MM_Retrieval_App/classification_model/train_model.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "source": [
    "run_training(max_steps=100, save_model='weights/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
